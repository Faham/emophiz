% 10 to 15 pages
% talk about various aspects of system's implementation and
% how it is integrated with the interactive technology
% - talk about the sensors and the fuzzy framework for emotion recognition
% and connect that to the game design elements

My goal is to adapt gameplay based on a player's affective state. Although there have not been studies investigating my particular question of how player experience is impacted by applying different mechanisms for affect-driven adjustments in games, there has been related work that can inform my research. Affective gaming has been defined by Gilleade et al. as an activity where ``the player's current emotional state is used to manipulate gameplay." ~\cite{gilleade2005affective}. Researchers have created and studied games that replace traditional game controls with affective game controls (e.g., the GSR-controlled dragons racing in `Relax-to-win' ~\cite{bersak2001intelligent} or the Electroencephalography-controlled balls rolling in `BrainBall' ~\cite{hjelm2003research}). Researchers have also investigating augmenting traditional game controls with affective game controls. For example, the Death Trigger side-scrolling shooter was played with a traditional gamepad and control scheme, but also adapted game elements (e.g., length of the flamethrower, size of the enemies, and the density of snowfall) using different physiological signals ~\cite{nacke2011biofeedback}. Finally, researchers have investigated adapting games using affective input. In work closest to mine, Dekker et al. ~\cite{dekker2007please} developed a game modification using the Source SDK and Half-Life 2, in which GSR and HR were used to control game shader graphics, screen shaking, and enemy spawn points (the number of locations in which enemies are put into the game world).  Kuikanniemi et al. ~\cite{kuikkaniemi2010influence} studied how awareness of the manipulation affected player experience in a first-person shooter (FPS), where affective input modulated character walking and turning speed, aiming direction, recoil amount, and firing rate. Their work revealed that players preferred to be aware of the adaptation.

This chapter explores various aspects of the affect engine developed and used in my study. I would show how the generic design of this system can be incorporated with any game engine and how can it be expanded for any other type of sensor and biofeedback data not necessarily used in this work. The first section talks about the overall design and different modules of the affect engine; the next sections describe different modules in detail giving examples of different settings used for my particular study. In final sections I present the game engine used in this work, and how I incorporated the affect engine in my experiments.

\section{Emotionally Adaptive Game System Design}

I will now present a basic system schematic of an emotionally adapted game in Figure ~\ref{fig:system-design}. A typical game engine depicted on the left-hand side of the diagram, continuously captures user input which is usually collected using gaming controllers such as gamepads or mouse and keyboard. % Emotionally Adapted Games - An Example of a First Person Shooter.pdf
This input data is then processed and transferred to the layer that handles the game's internal logical state, and the user input may influence the game state. After the logical state of the game is defined the system alters the actions of the synthetic agents in the game world, including the actions of computer-controlled non-player characters. The complexity of this AI layer varies greatly depending on the game. Based on the game state and the determined actions of the synthetic agents, the physics engine determines the movements of different objects within the world. Finally, the game world is synthesized for the player by rendering the graphical elements and producing and controlling the audio elements within the gamer ~\cite{saari2005emotional}. The proposed emotional regulation can be implemented as a middleware system that runs parallel to the game engine. The input processing layer of the game engine can receive a data flow of captured and pre-processed sensor data. The real-time signal processing may consist of different forms of amplifying, filtering and feature selection on the psychophysiological signals. This data flow may directly influence the state of the game world, or it can be used by the signal transformation sub-module to extract emotion values. This module consists of fuzzy rules for transformation of physiological signals into arousal and valence space and then the transformation from the arousal and valence space to emotion variables such as excitement, boredom and frustration. In addition, it contains a collection of design rules for narrative constructions and game object presentation within the game world. The outputs of the affect engine may then be applied to various actions of the game engine: i) the narrative state of the game world may be re-directed, ii) the game mechanics relating to the challenge balance might be altered or iii) the game might be adapted in its presentation layer such as visual or sound effects (non-game mechanic elements).
% Emotionally Adapted Games - An Example of a First Person Shooter.pdf

\img
{Emotion adaptive game system design}
{Emotion adaptive game system design}
{system-design.pdf}
{system-design}

% Emotionally Adapted Games - An Example of a First Person Shooter.pdf
% p With our system design for games it is possible for the game designer as well for the user to set desired emotional targets to be approached or avoided. The system uses both positive and negative feedback loops to determine the ideal adaptations case-by- case for game play for various emotional effects to be realized and managed. Indeed, to implement and evaluate some of the ideas presented, we have explored novel technical solutions and tested different kinds of psychophysiological adaptations that can be implemented. EMOShooter is a prototype platform for psychophysiologically adaptive 3D first-person shooter (FPS) gaming. It is built on top of open-source graphics engine (OGRE 3D) and physics engine (ODE). In this experimental platform we have the possibility to modify practically any game world element, player avatar, avatar outlook, or control parameter.  EMOShooter is a simple psychophysiologically adaptive game and hence a part of our emotionally adapted games definition. The system uses psychophysiological signals to influence the ease of use of the controls of the game hence affecting game play difficulty and game play experience. The system does not have target experiences systematically implemented at this moment nor does it have an emotion knob to tune the system. However, the EMOShooter game is a valuable example of one type of emotionally adapted games in demonstrating one feasible link between real-time emotional state measurement with psychophysiology and the game play. The goal of the EMOShooter game is to kill cube-like enemies either with sniper or machine gun. We have been testing various adaptation patterns with EMOShooter by primarily EDA and respiration as psychophysiological signals in our adaptive

% % Emotionally Adapted Games - An Example of a First Person Shooter.pdf
% p feedback system regards how these signals can be meaningfully connected to the actual game play via adapting game controls.  Adaptation of game controls includes changes in rate of fire, recoil, movement speed and shaking. If a player is aroused this will be reflected in EDA and respiration signals which in turn will make rate of fire and movement slower and will make the aim shaky. Hence, for a highly aroused player the game becomes more difficult. For a mildly aroused or calm player the controls become more efficient and easy to use hence facilitating performance at game play. Game events are mostly arousing. The amount of cubes to shoot, their approach and firing on the user, the amount of health left after being hit and the sound effects all are geared to drive up arousal in the game. The player's task is to be calm as indexed by psychophysiological signals to be able to operate the controls more efficiently. In our tests of the game we have collected also EMG data to infer the valence dimension of emotion during game play. In addition to the psychophysiological signals we have collected data from the players using behavioral game logging, video capture, interviews and questionnaires. During our tests we noticed that proper calibration and base lining of the psychophysiological signals is very important for the adaptations to work. We also noticed that having robust stimuli in the game is crucial for the adaptations to work because in many cases the stimulus functioned as a trigger in adaptation. The psychophysiological signals used are calibrated by using dynamic range (basically a variation of dynamic signal normalization algorithm), which has a memory buffer of a few seconds (depending on signal). Dynamic range is easy to use and effective calibration mechanism, and relative change seems to be more practical than absolute values in this kind of gaming.  According to our early analysis, there are three key issues in designing psychophysiologically adaptive games i) understanding the meaningful emotionally adaptive gaming patterns, ii) implementation of adaptation algorithms and signal processing, and iii) purposeful use of sensors in the game context [15]. The design patterns used in emotionally adaptive gaming must be meaningful and enjoyable for the player, and the utilization of signals must also obey the overall goal of the game. In order to achieve the goal player should find the right rhythm or balance of playing the game and control of psychophysiological responses and signals.   Signals should be analyzed as close to real-time as possible in psycho- physiologically adaptive gaming in order to keep the feedback loop in pace with the game adaptations and game events. We have used time-series analysis with short sample windows. In practice, ECG, EEG and EMG always require extensive data processing, but EDA and respiration can be almost used as such to create the adaptation signal. This implies that not all psychophysiological signals are equally open to be used as real-time inputs into an adaptive game at least in this stage of signal processing hardware and software development. Usability of psychophysiological recording devices remains quite poor. Respiration, HR [heart rate] and EDA are probably the easiest to implement. Also in case of emotional adaptation the design of the game may include the physical design of the sensors, e.g. “Detective hat” for EEG sensors or “Sniper-gloves” for EDA sensors. Hence, the sensors could be designed as part of the game story rather than presented as cumbersome and invasive laboratory-originated equipment.

The purpose of the initial study is to investigate physiological and affect-related responses in relation to an experimentally induced change in game mechanics. Note that in this study the affective loop is closed, that is, real-time affective indicators are directly influencing the game mechanics. The research question for the current investigation evolved around the components of my affective adaptation decisions: What game mechanics (player, NPC or environmental changes) lead to what kind of emotional state. This was investigated by means of a controlled experiment, as explained in the next section. In other words the purpose of my study is to evaluate the effects of design choices for affect-generated game adaptation on player experience. To compare different in-game adaptation approaches, I needed to implement three components:

\begin{itemize}
\item \textbf{Affect sensing}: An affect-detecting middleware engine (AME) to translate between physiological indicators of affect and actionable game input.
\item \textbf{Game Environment}: A game system with parameters suitable for adaptation via output from the sensed affect.
\item \textbf{Experience Evaluator}: A series of validated instruments integrated with the game environment to determine user experience during the experiment.
\end{itemize}

Fig. ~\ref{fig:system-design} shows a schematic flow diagram for the first two components, where an affect detection system depicted on the right feeds data to a typical game engine depicted on the left-hand side of the diagram.

% Creating an Emotionally Adaptive Game.pdf
% As a first step in creating an emotionally adaptive game, system input and output need to be specified in further detail. Regarding output (emotion-data), Saari et al. [22] provide an extensive discussion of possible elements to be adapted, structured by \"psychologically validated templates\". We have adopted a rather straightforward and intuitive \"template\": Game speed. We will manipulate the game's speed to influence the player's emotional state (the interplay between boredom, frustration and enjoyment, Fig. 1-left panel). Regarding system input (emotion-data), Öhman [23] distinguished three categories of emotion measures: Self-reports, overt behavior and physiological responses. Self-reports are frequently used for assessing players' emotions and experiences [5] but not suitable (since too obtrusive) for real-time application in a game. Regarding overt behavior, potentially useful techniques for measuring boredom, frustration and enjoyment are facial emotion tracking [24] and the analysis of posture and pressure exerted on the game controls [25]. Regarding physiological responses, there is an extensive field with many research findings in psychophysiology. Although the research is done in varying contexts with sometimes contradicting results, it is considered a highly interesting field for analyzing emotions in games. We have limited ourselves to the methods described below.

\section{Affect Middleware Engine}

The Affect Middleware Engine or AME is the software unit developed to transform collected physiological data into usable emotional states in real-time. While it is generally agreed that emotions can be inferred from three sources: subjective experience (e.g. feeling joyous), expressive behavior (e.g. smiling), and physiological activation (e.g. arousal) ~\cite{scherer1993neuroscience}, my affect engine provides a framework for transformation of physiological activations and some expressive behaviors. Fig. ~\ref{fig:affect-engine} is a schematic view of the signal transformation pipeline.

\img
{Affect engine modules}
{Affect engine modules}
{affect-engine.pdf}
{affect-engine}

% \largeimg
% {UML diagram of the Affect Middleware Engine}
% {UML diagram of the Affect Middleware Engine}
% {placeholder.png}
% {affect-engine-uml}

% Using emotional responses to increase the level of users interaction with a real-time play technology requires an effective technique to identifying specific emotion states within an emotional space. Major existing emotion models in the psychology literature includes: basic emotion theory ~\cite{ekman1992argument, ekman1992there} , dimensional emotion theory ~\cite{lang1995emotion, russell1980circumplex} and models from appraisal theory (e.g.,~\cite{roseman2001model}) ~\cite{zhang2010service}

Applications such as games can easily integrate the affect engine where emotion recognition can offer adaptive control to maintain user interest and engagement. Once connected via sensors to the emotion recognition system, the affective state of the user can be captured continuously and in real-time, and used as a secondary input for an enhanced interaction experience. The AME runs in two states, calibration and adaptation. When calibrating, the system waits for user input, attempting to discern sensible boundaries for physiological normalization according to the process described in ~\cite{mandryk2007fuzzy}. After a set period of time, the system enters adaptation mode, where data is fed into the signal transformation stage, and from there into the game engine. For longer play sessions, the system will periodically re-enter the calibration state to compensate for drift in the physiological signals. In this manner the system compensates for the difficulty of globally bounding physiological signals by approximating a series of local temporal bounds. A sample set for fuzzy rules used in the first and the second phase can be found in Appendix ~\ref{app:phys-to-av} and ~\ref{app:av-to-emotion}.

While the affect engine is capable of interpreting multiple physiological signals and performing a full fuzzy logic-based emotion inference according to the approach described in ~\cite{mandryk2007fuzzy}, I constrained ourselves to a simpler linear mapping for this experiment. Specifically, GSR signals were measured using a Thought Technology ProComp Infinity, connected to PC through a USB cable. Through the SensorLib API ~\cite{nacke2011biofeedback}, raw physiological inputs were received and basic filtering operations were performed. After the calibration period described above, the AME system began reporting normalized GSR signals to the game engine as a measure of player excitement or arousal ~\cite{aggag2011affective, tijs2009creating}. Fig. ~\ref{fig:sample-connected-system} shows a schematic view of a sample connected system components.

\img
{Sample connected system}
{Sample connected system with GSR and EMG sensors attached}
{sample-connected-system.png}
{sample-connected-system}

\subsection{Sensor Module}

Heart rate (HR), blood pressure, respiration, electrodermal activity (EDA) and galvanic skin response (GSR), as well as facial EMG (Electromyography) are of physiological variables correlated with various emotions. % Creating an Emotionally Adaptive Game.pdf
For cardiovascular activity, tonic (long-term, as opposed to phasic) heart rate (HR) is known to increase with sympathetic nervous system activity, such as emotional arousal and cognitive effort and stress. On the other hand, increases in attention (mediated in the parasympathetic nervous system) lead to a decreased heart rate ~\cite{ravaja2004contributions}. Yannakakis et al. ~\cite{yannakakis2008entertainment} found HR features to correlate with self-reported fun in games. %Heart rate variability (HRV) is considered an index for mental effort (e.g. ~\cite{vicente1987spectral}). Some researchers (e.g. ~\cite{veltman1993indices}) consider the percentage power in the low-frequency (LF) 0.070.14 Hz range as a particularly effective index for task-related mental effort / sympathetic activity. Respiratory responses are analyzed to control for respiratory artifacts in e.g. HRV (a phenomenon known as respiratory sinus arrhythmia). Respiration may, however, also be used as a measure itself, e.g. for investigating stress and mental load ~\cite{wientjes1992respiration}. Electrodermal activity (EDA) concerns the electrical resistance of the skin, also known as Skin Conductance (SCL, SCR) or Galvanic Skin Response (GSR).
Skin conductance is known to increase with information processing and the frequency of non-specific skin responses increases with arousal ~\cite{ravaja2004contributions}. %Electromyography (EMG) is a technique for measuring muscle activity; electric potential is being generated when muscle cells contract.
Facial EMG is frequently used as a metric for valence. %The most frequently analyzed facial muscles in this context are the orbicularis oculi (OO, used for closing the eyelids), zygomaticus major (ZYG, smiling) and corrugator supercilii (CORR, frowning). Most studies find positive correlations between valence and the OO and ZYG muscles, and a negative correlation between valence and CORR muscle (see e.g. [31], [32], [33]). In addition to the above findings, there are also a considerable number of studies without significant findings [34]. Because of the large differences in physiological responses between individuals and within individuals over time (autonomic response stereotypy principle, see e.g. [15], [35]), some researchers (e.g. [36]) argue for normalizing physiological data to facilitate a group analysis of the data. Additionally, affective systems should employ a battery of physiological features for accurate emotion predictions (e.g. [37]), and should allow for user-control for the sake of autonomy, privacy and interpretation of the data [41]. % Creating an Emotionally Adaptive Game.pdf
The sensor module consists of a Thought Technology ProComp Infinity encoder ~\cite{tt2013procomp} Figure ~\ref{fig:encoder}, connected to PC with a USB cable, SensorLib as the basic application programming interface (API) receives raw physiological inputs from the encoder driver and provides functionalities to apply different filters such as low-pass, high-pass, smoothing and shifting to the signal.

\subsection{Fuzzification Module} \label{subsec:fuzzi}
Interpreting physiological measures into emotion state can be difficult, due to noisy and inaccurate signals, however recent on-going studies in this area by Mandryk and Atkins ~\cite{mandryk2007fuzzy} presented a method to continuously identifying emotional states of the user while playing a computer game. Using the dimensional emotion model and fuzzy logic, based on a set of physiological measures, the fuzzy model transforms GSR, HR, facial EMG (for frowning and smiling) into arousal and valence variables. In the second phase another fuzzy logic model is used to transform arousal and valence variables into five basic emotion states including: boredom, challenge, excitement, frustration and fun (Figure ~\ref{fig:fuzzy-transformation}). Their study successfully revealed self-reported emotion states for fun, boredom and excitement are following the trends generated by their fuzzy transformation. %The advantage of continuously and quantitatively assessing user's emotional state during an entire play by their fuzzy logic model is what makes their model perfect to be in incorporated with real-time play technologies. Therefore extracting user's emotional state as a new class of unconscious inputs to the play technology.
Because their system responded in near real-time, it is a promising candidate for use as the basis for an adaptive engine.

\largeimg
{DotFuzzy Application used to define set of fuzzy rules and store it in XML format ~\ref{app:gsr-hr-to-arousal}}
{DotFuzzy Application}
{dotfuzzy.png}
{dotfuzzy}

\subsection{Emotion Monitor}
Emotion monitor is a debugging and adjustment module. Using this module emotion values along with basic physiological signals and transformed arousal and valence variables can monitored in real-time. This module also shows AME state while switching between calibration and adaptation states making it easier for designers to see how changes in AME states might affect various game-play situations.

% \largeimg
% {Emotion Monitor}
% {Emotion Monitor}
% {placeholder.png}
% {emotion-monitor}

% \section{Sensors}
% While the modular design of the Affect Engine allows its expansion for support of any physiological measures, currently the system uses Blood Volume Pulse (BVP), Galvanic Skin Response (GSR) and Electromyography (EMG; for frowning and smiling), to classify human affective states in 2-dimensional valence/arousal space (Figure \ref{fig:russel-av-space}).

% \subsection{Blood Volume Pulse and Heart Rate}
% The Blood Volume Pulse (BVP, Figure \ref{fig:bvp-sensor}) is a relative measure of the amount of blood owing in a vessel. Using BVP we calculated heart rate and heart rate variability. The heart rate is known to reflect emotional activity and has been used to differentiate between both negative and positive emotions as well as different arousal levels ~\cite{tt2013procomp}.

% \subsection{Galvanic Skin Response}
% The Galvanic Skin Response (GSR, Figure \ref{fig:gsr-sensor}) is useful to measure the skin's conductance between two electrodes and is a function of sweat gland activity and the skin's pore size. As a person becomes more or less stressed, the skin's conductance increases or decreases proportionally ~\cite{picard2003affective}.

% \subsection{Facial Electromyography}

\section{Game Environment}
To evaluate the impact of feedback on player experience, it was also necessary to implement a game environment that could be linked to the output of the AME. I chose to implement a straightforward zombie survival game based on the Half Life 2 engine in the genre of first-person shooters (FPS). A custom map (shown in Fig. ~\ref{fig:map-of-level}) was implemented. Using the Source Software Development Kit (Source SDK). The map was composed of a small outdoor area and three buildings. Zombies (Fig. ~\ref{fig:zombie}) spawned in waves from one of 10 points, and would undertake standard Half Life 2 zombie AI behavior, looking for the player and attacking with either thrown objects when distant (weakly damaging the player) or a melee attack when close (heavily damaging the player). A good default strategy for the player was to keep the zombies at a distance, eliminating them with their moderately powerful machine gun, and not allowing them to close to melee range. The player is tasked with surviving as many waves of zombies as possible, and accrues a score based on the number of zombies killed. The player is equipped with a machine gun with unlimited ammunition and a limited number of grenades. Health packs, which restore players from received damage, and additional grenades are available at defined locations. If a player presses a button at that location, a health pack will dispense and the button will be disabled until a cool down timer has expired.% (Figure ~\ref{fig:health-pack-button}).

\largeimg
{My custom map level created using the Source SDK and Half-Life 2}
{Map level created using the Source SDK and Half-Life 2}
{map-of-level.png}
{map-of-level}

Aspects of the game can be adjusted in real time based on the output of the AME system. In the implementation used in my study, the system could be in one of three states based on the normalized GSR value supplied from the AME. If players fell below a threshold of excitement as indicated by normalized GSR, then the system inferred that they were bored and increased the difficulty of the game. If players were above a threshold of normalized GSR, the system inferred that they were over-stimulated and made the game easier. If neither of these states were true, then the system assumed that they were playing normally and no adjustment occurred. The equations by which the game parameters were adjusted are also shown in Table ~\ref{tbl:adjustment-strategy}. While no action was taken unless normalized GSR was in the excited or bored band, once in that band, the game parameters adjusted continuously with the value of the GSR. Constants in the equations and the threshold values for excited and bored were adjusted manually, based on design experience and play testing prior to the experiment.

%-----------------------------------------------------------
\begin{table*}[!t]
\caption{Adjustment Strategy}
\label{tbl:adjustment-strategy}
\hfil
\centering
\begin{tabular}{lp{4cm}p{4cm}p{4cm}}
                     & Player                            & NPC                             & Environment \\
\hline
Excited              & Increase player speed \newline Increase grenade rate
                     & Decrease zombie speed \newline Decrease zombie crowd
                     & Decrease fog density \newline Increase med-pack rate  \\
\hline
Not excited          & Decrease player speed \newline Decrease grenade rate
                     & Increase zombie speed \newline Increase zombie crowd
                     & Increase fog density \newline Decrease med-pack rate  \\
\hline
Adaption \newline
equation             & $P_{speed} = 0.65 + 1.35 * Arousal$    \newline $G_{delay} = 40 - 20 * Arousal$
                     & $Z_{speed} = \frac{1}{0.30 + Arousal}$ \newline $Z_{crowd} = 3.75 - 2.5 * Arousal$
                     & $F_{start} = 70 + 380 * Arousal$       \newline $F_{end} = 500 + 1000 * Arousal$ \newline $M_{delay} = 100 - 60 * Arousal$ \\
\end{tabular}
\end{table*}
%-----------------------------------------------------------

\largeimg
{Zombie model that attack player as enemy}
{Zombie model}
{zombie.png}
{zombie}

% \largeimg
% {Health pack dispense button}
% {Health pack dispense button}
% {placeholder.png}
% {health-pack-button}

%\subsection{Level Design}
%todo: talk about Modding Half Life EP2

\largeimg
{Hammer level editor from the Source}
{Hammer level editor}
{hammer-editor.png}
{hammer-editor}

\section{Game Adaptation}
The game can be adapted in numerous ways based on the output of the AME. My research interest is in how different in-game adaptation mechanisms affect player experience. To explore in-game adaptation, I adapt either the player's abilities, the zombies' abilities or the environment. Table I shows the types of adjustments that can occur, which I describe next.

\subsection{Player}
Player modifications are any modifications that directly affected player state, even if the environment mediated those modifications. This is one of the popular strategies for dynamically balancing games. Figure ~\ref{fig:gow-2-poseidons-rage} shows Kratos in God of War 2 using Poseidon's Rage to eliminate enemies. Specifically, to adapt the player's abilities, I vary the player's speed (at which they can move around the environment) and the rate of grenade respawn in the player's weapon. Higher player speeds enabled the player to more easily escape the zombie melee attacks. The respawn rate of grenades impacted the player's ability to inflict damage by essentially giving them more powerful weapons.

\largeimg
{God of War 2, Poseidon's rage}
{God of War 2, gamer supposed to get excited through changes applied to player character}
{gow-2-poseidons-rage.jpg}
{gow-2-poseidons-rage}

\subsection{NPC}
Manipulating NPCs to make changes in game challenges is another major approach used in many video games. Figure ~\ref{fig:risen-2-boss-fight} shows Risen 2 boss fight and how NPCs visual and mechanics changes can affect players affective state. To adapt the non-player character zombies (NPCs), I can vary the speed at which the zombies move and the number of zombies (the size of the attacking crowd). The number of zombies spawned per unit time obviously increases the difficulty of the game. Increasing the speed of the zombie with respect to the player made it more difficult for the player to evade the zombie melee attacks. This manipulation is interesting as it is similar to the player speed adjustment from the perspective of game balance (i.e., the relative speed of the player and the enemy varies using both approaches), but applying the adaptation to the player or the NPC could result in different game experiences.

\largeimg
{Risen 2 boss fight}
{Risen 2 boss fight, gamer supposed to get excited through changes applied to the NPC}
{risen-2-boss-fight.jpg}
{risen-2-boss-fight}

\subsection{Environment}
To adapt the environment, I vary the density of ambient fog, which was proportionate to the distance that the player could see. By constraining the players' viewing distance with increasing fog, zombies could approach closer, leaving the player with less time to target them before they closed to within melee range. I also varied the rate at which health packs respawned in the environment. Giving players the ability to find more health packs affected their ability to take damage; however, this required player interaction with the environment (i.e., picking up the health pack) as opposed to better equipping the player directly (e.g., having players health regenerate over time). Figure ~\ref{fig:risen-boss-fight} shows an example of environment adaptation in today video games.

\largeimg
{Risen boss fight}
{Risen boss fight, gamer supposed to get excited through changes applied to environment}
{risen-boss-fight.jpg}
{risen-boss-fight}

\section{Evaluation System}
Evaluation of the system was carried out in three ways. First, all physiological signals were logged to ensure that the system was working correctly and as a basis for comparison. Second, game events were logged to track how the player reacted to adaptive game mechanics. Finally, players were given experience surveys after the completion of each level.

%-----------------------------------------------------------
\begin{figure}
  \centering
\begin{lstlisting}[frame=none]
time, raw, transformed
811913, -0.784929931163788, 78.1241008746691
812026, -0.784929931163788, 76.2492447347221
812135, -0.784722805023193, 75.6241728046956
812243, -0.784515619277954, 74.3742087697088
812349, -0.784515619277954, 74.3742087697088
812459, -0.784515619277954, 74.3742087697088
812571, -0.784515619277954, 74.9992806997353
812680, -0.784515619277954, 75.6243526297618
812790, -0.784515619277954, 77.499388594775
812880, -0.784515619277954, 74.3742087697088
\end{lstlisting}
  \caption{In-game GSR log reporting about raw and transformed GSR values}
  \label{txt:log-gsr}
\end{figure}
%-----------------------------------------------------------

%-----------------------------------------------------------
\begin{figure}
  \centering
\begin{lstlisting}[frame=none]
time_millisecond, arousal, player_speed, zombie_speed, fog_start_dist, fog_end_dist, current_round, zombie_threshold, zombie_increase_power, max_zombie_alive, number_of_alive_zombies, number_of_killed_zombies, grenade_regen_delay, medic_regen_delay, calibrating, adaptation_condition
870368, 0,          1,        1, 300, 1000, 2, 8, 1.3, 7, 7, 6, 30,       30, 0, 2
870369, 0.9242272,  1.897707, 1, 300, 1000, 2, 8, 1.3, 7, 7, 6, 30,       30, 0, 2
870369, 0.9242272,  1.897707, 1, 300, 1000, 2, 8, 1.3, 7, 7, 6, 21.51546, 30, 0, 2
871373, 0.9304435,  1.906099, 1, 300, 1000, 2, 8, 1.3, 7, 7, 6, 21.51546, 30, 0, 2
871373, 0.9304435,  1.906099, 1, 300, 1000, 2, 8, 1.3, 7, 7, 6, 21.39113, 30, 0, 2
872379, 0.9327956,  1.909274, 1, 300, 1000, 2, 8, 1.3, 7, 6, 7, 21.39113, 30, 0, 2
872379, 0.9327956,  1.909274, 1, 300, 1000, 2, 8, 1.3, 7, 6, 7, 21.34409, 30, 0, 2
873382, 0.9732862,  1.963936, 1, 300, 1000, 2, 8, 1.3, 7, 5, 8, 21.34409, 30, 0, 2
873382, 0.9732862,  1.963936, 1, 300, 1000, 2, 8, 1.3, 7, 5, 8, 20.53428, 30, 0, 2
874389, 1,          2,        1, 300, 1000, 2, 8, 1.3, 7, 5, 8, 20.53428, 30, 0, 2
\end{lstlisting}
  \caption{In-game metrics log reporting about different adaptation details in each condition}
  \label{txt:log-metrics}
\end{figure}
%-----------------------------------------------------------
